{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection and CV estimators\n",
    "\n",
    "Authors: [Alexandre Gramfort](http://alexandre.gramfort.net)\n",
    "         [Guillaume Lemaitre](https://glemaitre.github.io/)\n",
    "         [Olivier Grisel](http://ogrisel.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter selection, Validation, and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most models have parameters that influence how complex a model they can learn. Remember using `KNeighborsRegressor`.\n",
    "If we change the number of neighbors we consider, we get a smoother and smoother prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/plot_kneigbors_regularization.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above figure, we see fits for three different values of ``n_neighbors``.\n",
    "For ``n_neighbors=2``, the data is overfit, the model is too flexible and can adjust too much to the noise in the training data. For ``n_neighbors=20``, the model is not flexible enough, and can not model the variation in the data appropriately.\n",
    "\n",
    "In the middle, for ``n_neighbors = 5``, we have found a good mid-point. It fits\n",
    "the data fairly well, and does not suffer from the overfit or underfit\n",
    "problems seen in the figures on either side. What we would like is a\n",
    "way to quantitatively identify overfit and underfit, and optimize the\n",
    "hyperparameters (in this case, the polynomial degree d) in order to\n",
    "determine the best algorithm.\n",
    "\n",
    "We trade off remembering too much about the particularities and noise of the training data vs. not modeling enough of the variability. This is a trade-off that needs to be made in basically every machine learning application and is a central concept, called bias-variance-tradeoff or \"overfitting vs underfitting\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/overfitting_underfitting_cartoon.svg\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters, Over-fitting, and Under-fitting\n",
    "\n",
    "Unfortunately, there is no general rule how to find the sweet spot, and so machine learning practitioners have to find the best trade-off of model-complexity and generalization by trying several hyperparameter settings. Hyperparameters are the internal knobs or tuning parameters of a machine learning algorithm (in contrast to model parameters that the algorithm learns from the training data -- for example, the weight coefficients of a linear regression model); the number of *k* in K-nearest neighbors is such a hyperparameter.\n",
    "\n",
    "Most commonly this \"hyperparameter tuning\" is done using a brute force search, for example over multiple values of ``n_neighbors``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 1, average score: 0.561570\n",
      "n_neighbors: 3, average score: 0.721538\n",
      "n_neighbors: 5, average score: 0.692041\n",
      "n_neighbors: 10, average score: 0.734941\n",
      "n_neighbors: 20, average score: 0.634634\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# generate toy dataset:\n",
    "x = np.linspace(-3, 3, 100)\n",
    "rng = np.random.RandomState(42)\n",
    "y = np.sin(4 * x) + x + rng.normal(size=len(x))\n",
    "X = x[:, np.newaxis]\n",
    "\n",
    "cv = KFold(shuffle=True, n_splits=5)\n",
    "\n",
    "# for each parameter setting do cross-validation:\n",
    "for n_neighbors in [1, 3, 5, 10, 20]:\n",
    "    scores = cross_val_score(KNeighborsRegressor(n_neighbors=n_neighbors), X, y, cv=cv)\n",
    "    print(\"n_neighbors: %d, average score: %f\" % (n_neighbors, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a function in scikit-learn, called ``validation_plot`` to reproduce the cartoon figure above. It plots one parameter, such as the number of neighbors, against training and validation error (using cross-validation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "n_neighbors = [1, 3, 5, 10, 20, 50]\n",
    "train_scores, test_scores = validation_curve(KNeighborsRegressor(), X, y, param_name=\"n_neighbors\",\n",
    "                                             param_range=n_neighbors, cv=cv)\n",
    "plt.plot(n_neighbors, train_scores.mean(axis=1), label=\"train accuracy\")\n",
    "plt.plot(n_neighbors, test_scores.mean(axis=1), label=\"test accuracy\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.xlim([50, 0])\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    Note that many neighbors mean a \"smooth\" or \"simple\" model, so the plot uses a reverted x axis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If multiple parameters are important, like the parameters ``C`` and ``gamma`` in an ``SVM`` (more about that later), all possible combinations are tried:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001000, gamma: 0.001000, average score: -0.005988\n",
      "C: 0.001000, gamma: 0.010000, average score: -0.080428\n",
      "C: 0.001000, gamma: 0.100000, average score: -0.019658\n",
      "C: 0.001000, gamma: 1.000000, average score: -0.044587\n",
      "C: 0.010000, gamma: 0.001000, average score: -0.067557\n",
      "C: 0.010000, gamma: 0.010000, average score: -0.050715\n",
      "C: 0.010000, gamma: 0.100000, average score: 0.009718\n",
      "C: 0.010000, gamma: 1.000000, average score: -0.015597\n",
      "C: 0.100000, gamma: 0.001000, average score: -0.089669\n",
      "C: 0.100000, gamma: 0.010000, average score: 0.147290\n",
      "C: 0.100000, gamma: 0.100000, average score: 0.508387\n",
      "C: 0.100000, gamma: 1.000000, average score: 0.502442\n",
      "C: 1.000000, gamma: 0.001000, average score: 0.197964\n",
      "C: 1.000000, gamma: 0.010000, average score: 0.593140\n",
      "C: 1.000000, gamma: 0.100000, average score: 0.629293\n",
      "C: 1.000000, gamma: 1.000000, average score: 0.706674\n",
      "C: 10.000000, gamma: 0.001000, average score: 0.558625\n",
      "C: 10.000000, gamma: 0.010000, average score: 0.634464\n",
      "C: 10.000000, gamma: 0.100000, average score: 0.605237\n",
      "C: 10.000000, gamma: 1.000000, average score: 0.724392\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# each parameter setting do cross-validation:\n",
    "for C in [0.001, 0.01, 0.1, 1, 10]:\n",
    "    for gamma in [0.001, 0.01, 0.1, 1]:\n",
    "        scores = cross_val_score(SVR(C=C, gamma=gamma), X, y, cv=cv)\n",
    "        print(\"C: %f, gamma: %f, average score: %f\" % (C, gamma, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is such a very common pattern, there is a built-in class for this in scikit-learn, ``GridSearchCV``. ``GridSearchCV`` takes a dictionary that describes the parameters that should be tried and a model to train.\n",
    "\n",
    "The grid of parameters is defined as a dictionary, where the keys are the parameters and the values are the settings to be tested.\n",
    "\n",
    "To inspect training score on the different folds, the parameter ``return_train_score`` is set to ``True``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv, verbose=3, return_train_score=True, n_jobs = -1)\n",
    "\n",
    "# n_jobs = -1) do the grid search in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the great things about GridSearchCV is that it is a *meta-estimator*. It takes an estimator like SVR above, and creates a new estimator, that behaves exactly the same - in this case, like a regressor.\n",
    "So we can call ``fit`` on it, to train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    8.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                           epsilon=0.1, gamma='auto_deprecated', kernel='rbf',\n",
       "                           max_iter=-1, shrinking=True, tol=0.001,\n",
       "                           verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10],\n",
       "                         'gamma': [0.001, 0.01, 0.1, 1]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What ``fit`` does is a bit more involved then what we did above. First, it runs the same loop with cross-validation, to find the best parameter combination.\n",
    "Once it has the best combination, it runs fit again on all data passed to fit (without cross-validation), to built a single new model using the best parameter setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, as with all models, we can use ``predict`` or ``score``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.79762875, -1.74054091, -1.71412904, -1.72272347, -1.76880247,\n",
       "       -1.8527208 , -1.97255382, -2.12407501, -2.30087676, -2.49463429,\n",
       "       -2.695503  , -2.89262935, -3.07474705, -3.23082299, -3.35071314,\n",
       "       -3.42578612, -3.44947391, -3.41771237, -3.32924127, -3.18574205,\n",
       "       -2.9918017 , -2.75470244, -2.48404785, -2.19124658, -1.88888388,\n",
       "       -1.59001819, -1.30744475, -1.05297034, -0.8367425 , -0.66667333,\n",
       "       -0.54799235, -0.4829551 , -0.4707249 , -0.50743515, -0.58642852,\n",
       "       -0.69865919, -0.83323456, -0.97806438, -1.12057877, -1.24847261,\n",
       "       -1.35043139, -1.41679516, -1.44012026, -1.41560488, -1.3413525 ,\n",
       "       -1.21845724, -1.05090633, -0.84530623, -0.61045003, -0.35675398,\n",
       "       -0.09559933,  0.16137852,  0.40300817,  0.61926205,  0.80185531,\n",
       "        0.94472644,  1.04437082,  1.10000798,  1.11357463,  1.08954695,\n",
       "        1.03460678,  0.95717608,  0.86685224,  0.7737823 ,  0.68801751,\n",
       "        0.61888941,  0.57444669,  0.56098656,  0.58270777,  0.64150352,\n",
       "        0.73690334,  0.86616306,  1.02449275,  1.20540425,  1.40115266,\n",
       "        1.60324152,  1.80295801,  1.99190412,  2.16249073,  2.3083654 ,\n",
       "        2.42474939,  2.50866621,  2.55905134,  2.57674055,  2.56434191,\n",
       "        2.52600389,  2.46709789,  2.39383845,  2.31286721,  2.23082834,\n",
       "        2.15396216,  2.0877418 ,  2.03657355,  2.00357681,  1.99045342,\n",
       "        1.99745004,  2.02341108,  2.06591373,  2.12147209,  2.18579347])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can inspect the best parameters found by ``GridSearchCV`` in the ``best_params_`` attribute, and the best score in the ``best_score_`` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7422680758335984\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But you can investigate the performance and much more for each set of parameter values by accessing the `cv_results_` attributes. The `cv_results_` attribute is a dictionary where each key is a string and each value is array. It can therefore be used to make a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_C', 'param_gamma', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 'split3_train_score', 'split4_train_score', 'mean_train_score', 'std_train_score'])\n"
     ]
    }
   ],
   "source": [
    "print(grid.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.001306</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.001}</td>\n",
       "      <td>-0.006906</td>\n",
       "      <td>-0.151779</td>\n",
       "      <td>-0.059555</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083365</td>\n",
       "      <td>0.072167</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.001629</td>\n",
       "      <td>-0.007875</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>-0.002341</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>-0.002259</td>\n",
       "      <td>0.002993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.01}</td>\n",
       "      <td>-0.004390</td>\n",
       "      <td>-0.148643</td>\n",
       "      <td>-0.056922</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080611</td>\n",
       "      <td>0.071976</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>-0.005399</td>\n",
       "      <td>0.002762</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.002983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.1}</td>\n",
       "      <td>0.006453</td>\n",
       "      <td>-0.135150</td>\n",
       "      <td>-0.046389</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068952</td>\n",
       "      <td>0.070935</td>\n",
       "      <td>16</td>\n",
       "      <td>0.010832</td>\n",
       "      <td>0.004821</td>\n",
       "      <td>0.014088</td>\n",
       "      <td>0.010056</td>\n",
       "      <td>0.013507</td>\n",
       "      <td>0.010661</td>\n",
       "      <td>0.003297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 1}</td>\n",
       "      <td>0.004755</td>\n",
       "      <td>-0.138332</td>\n",
       "      <td>-0.048042</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070984</td>\n",
       "      <td>0.071069</td>\n",
       "      <td>17</td>\n",
       "      <td>0.009713</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>0.012927</td>\n",
       "      <td>0.008912</td>\n",
       "      <td>0.012464</td>\n",
       "      <td>0.009379</td>\n",
       "      <td>0.003597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.001}</td>\n",
       "      <td>-0.004131</td>\n",
       "      <td>-0.148318</td>\n",
       "      <td>-0.056645</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080328</td>\n",
       "      <td>0.071963</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>-0.005125</td>\n",
       "      <td>0.003006</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.002955</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.002969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.001306      0.000043         0.001170        0.000023   0.001   \n",
       "1       0.001186      0.000075         0.001537        0.000498   0.001   \n",
       "2       0.001424      0.000528         0.001330        0.000428   0.001   \n",
       "3       0.001407      0.000750         0.001076        0.000203   0.001   \n",
       "4       0.000994      0.000171         0.000992        0.000187    0.01   \n",
       "\n",
       "  param_gamma                        params  split0_test_score  \\\n",
       "0       0.001  {'C': 0.001, 'gamma': 0.001}          -0.006906   \n",
       "1        0.01   {'C': 0.001, 'gamma': 0.01}          -0.004390   \n",
       "2         0.1    {'C': 0.001, 'gamma': 0.1}           0.006453   \n",
       "3           1      {'C': 0.001, 'gamma': 1}           0.004755   \n",
       "4       0.001   {'C': 0.01, 'gamma': 0.001}          -0.004131   \n",
       "\n",
       "   split1_test_score  split2_test_score  ...  mean_test_score  std_test_score  \\\n",
       "0          -0.151779          -0.059555  ...        -0.083365        0.072167   \n",
       "1          -0.148643          -0.056922  ...        -0.080611        0.071976   \n",
       "2          -0.135150          -0.046389  ...        -0.068952        0.070935   \n",
       "3          -0.138332          -0.048042  ...        -0.070984        0.071069   \n",
       "4          -0.148318          -0.056645  ...        -0.080328        0.071963   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0               20           -0.001629           -0.007875   \n",
       "1               19            0.000635           -0.005399   \n",
       "2               16            0.010832            0.004821   \n",
       "3               17            0.009713            0.002878   \n",
       "4               18            0.000859           -0.005125   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.000267           -0.002341            0.000282   \n",
       "1            0.002762           -0.000008            0.002721   \n",
       "2            0.014088            0.010056            0.013507   \n",
       "3            0.012927            0.008912            0.012464   \n",
       "4            0.003006            0.000224            0.002955   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0         -0.002259         0.002993  \n",
       "1          0.000142         0.002983  \n",
       "2          0.010661         0.003297  \n",
       "3          0.009379         0.003597  \n",
       "4          0.000384         0.002969  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cv_results = pd.DataFrame(grid.cv_results_)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.742268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.701670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.650180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.648874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.606527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C param_gamma  mean_test_score\n",
       "19      10           1         0.742268\n",
       "15       1           1         0.701670\n",
       "14       1         0.1         0.650180\n",
       "18      10         0.1         0.648874\n",
       "17      10        0.01         0.606527"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_tiny = cv_results[['param_C', 'param_gamma', 'mean_test_score']]\n",
    "cv_results_tiny.sort_values(by='mean_test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a problem with using this score for evaluation, however. You might be making what is called a **multiple hypothesis testing error**. If you try very many parameter settings, some of them will work better just by chance, and the score that you obtained might not reflect how your model would perform on new unseen data.\n",
    "Therefore, it is good to split off a separate test-set before performing grid-search. This pattern can be seen as a training-validation-test split, and is common in machine learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/grid_search_cross_validation.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this very easily by splitting of some test data using ``train_test_split``, training ``GridSearchCV`` on the training set, and applying the ``score`` method to the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidibe/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the parameters that were selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some practitioners go for an easier scheme, splitting the data simply into three parts, training, validation and testing. This is a possible alternative if your training set is very large, or it is infeasible to train many models using cross-validation because training a model takes very long.\n",
    "You can do this with scikit-learn for example by splitting of a test-set and then applying GridSearchCV with ShuffleSplit cross-validation with a single iteration:\n",
    "\n",
    "<img src=\"figures/train_validation_test2.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............... C=0.001, gamma=0.001, score=-0.027, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ................ C=0.001, gamma=0.01, score=-0.026, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ................. C=0.001, gamma=0.1, score=-0.018, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................... C=0.001, gamma=1, score=-0.018, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ................ C=0.01, gamma=0.001, score=-0.025, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ................. C=0.01, gamma=0.01, score=-0.008, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................... C=0.01, gamma=0.1, score=0.070, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ..................... C=0.01, gamma=1, score=0.063, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ................. C=0.1, gamma=0.001, score=-0.007, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................... C=0.1, gamma=0.01, score=0.164, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] .................... C=0.1, gamma=0.1, score=0.538, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ...................... C=0.1, gamma=1, score=0.515, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.182, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.678, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ...................... C=1, gamma=0.1, score=0.790, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........................ C=1, gamma=1, score=0.861, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.681, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.734, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ..................... C=10, gamma=0.1, score=0.814, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] ....................... C=10, gamma=1, score=0.910, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "single_split_cv = ShuffleSplit(n_splits=1)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=single_split_cv, verbose=3)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much faster, but might result in worse hyperparameters and therefore worse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidibe/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(SVR(), param_grid=param_grid)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>:\n",
    "     <ul>\n",
    "      <li>\n",
    "      Apply grid-search to find the best setting for the number of neighbors in ``KNeighborsClassifier``, and apply it to the digits dataset.\n",
    "      </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)\n",
    "\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guided hyper-optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper-optimization of parameters was done up to now by giving some values to be tried. Usually, we could automatically generated those values (randomly or not) by using `RandomSearchCV` or `GridSearchCV`.\n",
    "\n",
    "We could do a little be better by trying some parameters which we could consider more probable to optimize our problem depending on the previous parameters which we used before.\n",
    "\n",
    "We will use `scikit-optimize` and `optuna` to do so. We will use the small Boston regression\n",
    "dataset to limit the computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "boston = load_boston()\n",
    "X, y = boston.data, boston.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y\n",
    ")\n",
    "\n",
    "n_features = X.shape[1]\n",
    "\n",
    "# gradient boosted trees tend to do well on problems like this\n",
    "reg = GradientBoostingRegressor(\n",
    "    n_estimators=50, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [50, 100, 150],\n",
    "              'max_depth': [3, 5, 8]}\n",
    "grid = GridSearchCV(reg, param_grid=param_grid, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(grid.cv_results_).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter search with scikit-optimize\n",
    "\n",
    "We will use Gaussian Processes to drive the hyper-parameters optimization. We need to give a range of data to use for each parameter that we want to optimize. In addition, we need to create the objective function which we want to minimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "\n",
    "# The list of hyper-parameters we want to optimize. For each one we define the bounds,\n",
    "# the corresponding scikit-learn parameter name, as well as how to sample values\n",
    "# from that dimension (`'log-uniform'` for the learning rate)\n",
    "space  = [Integer(1, 5, name='max_depth'),\n",
    "          Real(10**-5, 10**0, \"log-uniform\", name='learning_rate'),\n",
    "          Integer(1, n_features, name='max_features'),\n",
    "          Integer(2, 100, name='min_samples_split'),\n",
    "          Integer(1, 100, name='min_samples_leaf')]\n",
    "\n",
    "# this decorator allows your objective function to receive a the parameters as\n",
    "# keyword arguments. This is particularly convenient when you want to set scikit-learn\n",
    "# estimator parameters\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    reg.set_params(**params)\n",
    "\n",
    "    return -np.mean(cross_val_score(reg, X, y, cv=5, n_jobs=-1,\n",
    "                                    scoring=\"neg_mean_absolute_error\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once those steps performed, we need to call the the optimization loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import gp_minimize\n",
    "res_gp = gp_minimize(objective, space, n_calls=50, random_state=0)\n",
    "\n",
    "\"Best score=%.4f\" % res_gp.fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the best parameters obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Best parameters:\n",
    "- max_depth=%d\n",
    "- learning_rate=%.6f\n",
    "- max_features=%d\n",
    "- min_samples_split=%d\n",
    "- min_samples_leaf=%d\"\"\" % (res_gp.x[0], res_gp.x[1], \n",
    "                            res_gp.x[2], res_gp.x[3], \n",
    "                            res_gp.x[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we can check the objective function values depending of the number of time we are calling it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from skopt.plots import plot_convergence\n",
    "\n",
    "plot_convergence(res_gp);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter search with Optuna\n",
    "\n",
    "URL : https://pypi.org/project/optuna/\n",
    "\n",
    "See video : https://www.youtube.com/watch?v=J_aymk4YXhg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 32)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 10**-5, 10**0)\n",
    "    max_features = trial.suggest_int('max_features', 1, n_features)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 100)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 100)\n",
    "\n",
    "    reg = GradientBoostingRegressor(\n",
    "        max_depth=max_depth, n_estimators=50,\n",
    "        max_features=max_features,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "    return -np.mean(cross_val_score(reg, X, y, cv=5, n_jobs=-1,\n",
    "                                    scoring=\"neg_mean_absolute_error\"))\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "optuna.logging.disable_default_handler()  # limit verbosity\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Show best result\n",
    "print(study.best_trial.params)\n",
    "print(study.best_trial.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [t.value for t in study.trials]\n",
    "plt.plot(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [t.value for t in study.trials]\n",
    "values = [np.min(values[:k]) for k in range(1, len(values))]\n",
    "plt.plot(values)\n",
    "plt.xlabel('Trials')\n",
    "plt.ylabel('MAE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>:\n",
    "     <ul>\n",
    "      <li>\n",
    "      Repeat the experiment on the original toy data and try to automatically optimize the parameter `C` and `gamma` of a SVR model.\n",
    "      </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
